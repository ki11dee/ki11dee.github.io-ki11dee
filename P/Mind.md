# What is Mind??
What exactly is the flow of human thought and consciousness? Where does this thing we call *mind* originate, and how does it come about? Where is the human mind actually located? Could it be in the heart or chest, as Aristotle suggested? Or in the head, as Plato argued? Or might it be something akin to an intangible soul, one that perhaps cannot even be separated from the physical body? Such discussions about the *mind-body problem* have a long and intricate history. Capturing the essence of consciousness is no easy task, as it remains a largely subjective concept. In philosophy, even establishing that we have minds at all is no simple certainty, let alone affirming whether others possess them. At least in modern medical and scientific circles, there is a widely accepted view that human consciousness is produced by the brain—a straightforward yet powerful stance that easily eclipses many philosophical debates.
In scientific terms, consciousness is often defined as *awareness of oneself and one's environment.* In neuroscience, consciousness is likened to the brain’s network structure: imagine drawing a probability distribution that increases as it descends from a high level, and let us define regions with more stability compared to the surrounding areas as *attractors.* In such an attractor, the brain network behaves in a particular manner; when two or more attractors emerge or shift to another attractor, the brain network changes its operational behavior. For example, the state of the brain during NREM sleep versus when we are fully awake can be represented by different attractor maps. Thus, one might consider consciousness as a specific network in an attractor state.
But then, where precisely does consciousness reside within the brain? One of the frustrations faced by physicians dealing with patients who have sustained brain damage, and are thus unresponsive to external stimuli, is this very question. If consciousness were indeed localized in a particular area, one could determine its presence simply by evaluating the extent of damage to that region. Yet, the reality is far more complex. Medicine currently subscribes to Tononi’s Integrated Information Theory (IIT), which posits, among other things, that the cerebellum is not involved in consciousness, and splitting the corpus callosum of the cerebrum can generate new conscious experiences. In fact, the brain is structurally unintegrated. However, the neuronal networks inside the brain tell a different story. The neurons are interwoven into an intricate, complex system. Does this interconnectedness follow any specific rules or patterns?
The Neural Information System (NIS) of our brain consists of:
> Neurons that transmit electricity and communicate chemically across tiny gaps, 

> Systems, each responsible for specific functions in distinct areas of the brain, and

> Integration of the processed information between these systems, forming perceptions, memories, thoughts, language, attitudes, and other learned experiences.

In cognitive neuroscience, Daniel Kahneman introduced the dual-processing theory, which divides perception, memory, thought, language, attitudes, and other experiences into two layers: automatic processing and controlled processing. These two layers enable us to equate even psychological experiences that are challenging to describe—such as thoughts, emotions, or even spiritual experiences—to biological mechanisms. Overall, science’s conclusion about cognition sides with Plato’s view (though not in a Platonic sense, as modern science completely rejects the notion of a separable soul); in science, the mind is simply a bio-psycho-social interaction. Sometimes, it even goes down to the most basic systems, as Richard Dawkins argued with his selfish gene. Science indeed reduces the human mind to something akin to a mechanical mechanism, but there remain unresolved parts that prevent us from finalizing the ambiguous concept of the mind into a definitive statement. Though our brains are far more complex than those of other animals, the fundamental workings of the NIS in humans and other animals are virtually indistinguishable at lower levels. Nevertheless, the human mind appears to possess something uniquely exceptional. What is it that elevates our consciousness? To solve this puzzle, we must revisit the concept of consciousness itself.
We know that consciousness involves a series of processes that enable us to "search ourselves and our environment, ensuring that perceptions, memories, and thoughts are accurately represented in awareness." Notably, consciousness clearly comprises some kind of formal system, and such a system draws ideas similarly from various methodologies (sometimes to the point where those methodologies produce art).

# The Intelligence
There are multiple ways to quantify intelligence, and it varies depending on the categorization method employed. For example, Sternberg's model divides intelligence into three types: analytical, creative, and practical. This model is often utilized in fields like Cultural Dimension Theory (CDT) or management studies. In contrast, the Wechsler Adult Intelligence Scale (WAIS) is mainly used for clinical diagnostic purposes, and it is the only intelligence assessment model with legal validity and scientific credibility.
In WAIS, the population average is set at 100, with a standard deviation (SD) of 15. It is important to note that not all tests use the same standard deviation. For instance, the test administered by MENSA Korea resembles the perceptual reasoning subset of the WAIS and uses an SD of 24 for normalization. Thus, a score of IQ 160 on the MENSA Korea test is equivalent to an FSIQ score of 138 on the WAIS. Conversely, scoring an FSIQ of 160 (perfect scores across all subtests) on WAIS would translate to an IQ of 196 on the MENSA Korea test—a rather exceptional and near-unhuman level.
Currently, the mainstream theory in cognitive science that describes intelligence is the Cattell-Horn-Carroll (CHC) theory, which divides intelligence into general intelligence and subordinate components, specifically crystallized intelligence and fluid intelligence. The concept of *theory of mind* as discussed in developmental psychology seems distinct from what I originally understood in philosophical psychology. To avoid confusion, I will refer to the former as ToM and the latter as PoM.
ToM refers to a specific socio-cognitive ability that enables young children to begin understanding the perspectives of others, often used to diagnose developmental conditions such as autism spectrum disorders (ASD), as seen in diagnostic tools like CARS or ADOS. In other words, the notion of ToM involves positing an imagined mental faculty to assess one’s capacity for empathy and understanding of others.
However, ToM falls short of fully explaining non-severe autism spectrum cases involving intellectual disabilities that can be detected in early childhood. On average, about 40% of individuals with autism spectrum disorders (ASD) possess above-average FSIQ, leading to a phenomenon called *masking* where individuals mimic the behavior of neurotypical individuals to fit in once they accumulate sufficient experiential knowledge. According to CHC theory, socialization in individuals with ASD may be linked to crystallized intelligence (Gc), which encompasses the ability to acquire and apply social knowledge. This ability is correlated with general intelligence (g).
The extent of empathy is related to sociability, whereas social competence is more closely tied to one's ability to infer and apply unspoken social rules. Hence, social competence is not some mysterious entity disconnected from intelligence; rather, much of it is likely shaped by learning and development, even during early childhood, as influenced by logical reasoning and fluid intelligence (Gf). It follows that the degree of such reasoning abilities typically correlates with performance on the Wechsler scales. Therefore, interpreting better outcomes among ASD individuals with higher intelligence as being attributable to IQ is a more plausible perspective compared to the limitations of ToM.
If we follow this line of reasoning, we may say that after the formative period of identity development, the human brain enters a plastic state of Gf transitioning into Gc. Thus, it might be possible to define individuals with low intrinsic cognitive flexibility as simply falling within the autism spectrum.
Additionally, a recent theory called the Parieto-Frontal Integration Theory (P-FIT) has emerged, which explains intelligence based on the locations of the frontal and parietal lobes—specific areas of the brain that are highly activated during intellectual activity—as well as the structure and function of the neural networks within them. This sounds fascinating, and I plan to explore it after reviewing a general overview of neuroscience.

# Boundaries of Mind and Consciousnes
What is the mind, and is consciousness synonymous with the mind? I believe the term "consciousness" is more apt when addressing the mind from a scientific perspective, whereas "mind" seems to imply a more metaphysical concept. Tononi's dual-processing theory approaches the mind through the framework of consciousness and unconsciousness, but it encounters the problem of the blurred boundary between these states. In neuroscience, this boundary itself does not exist, and consciousness is simply the collective state of the neural network. Psychology, however, divides consciousness into emotion, cognition, and behavior. Philosophical psychology categorizes these layers into three components as well, with more granularity:
> [1] Phenomenal Consciousness: Often referred to by the term *qualia* in philosophy, this component refers to the experiential state of indescribable sensations. For example, it is impossible to convey the feeling of *seeing* to someone born blind. Another example might be the pain experienced from a blow to the testicles that women cannot perceive, or the pain of pregnancy and childbirth that men cannot experience. As Ramanujan once described his intuitive mental abilities, attributing them to a goddess named Namagiri, the origin of intuitive inspiration can be similarly enigmatic. Phenomenal experiences are biologically constrained; without direct experience, understanding is impossible, and even if I have had the experience, it is also impossible to convey the information to someone who has not experienced it. In short, sensations themselves cannot be fully converted into language.

> [2] Access Consciousness: This refers to executive functions used to rationally control speech and behavior and facilitate (logical) reasoning. It is related to working memory, which encompasses all types of short-term and long-term memories, such as learned experience, recollections, and general knowledge. It can be understood as the process of *thinking* about the sensations one experiences in [1]. Thus, unconscious or emotional control does not belong in this category. For example, consider a situation in which one is able to regulate emotional impulses and behave rationally in public, despite being extremely angry. In this case, it may seem as though one is *controlling behavior* consciously, but in fact, the behavior itself is not being consciously controlled, which is why it does not fall under access consciousness.

> [3] Self-Consciousness and Monitoring Consciousness: Self-consciousness involves being aware of oneself as the subject of experience—identifying oneself, questioning one's identity, or becoming aware of the physical body associated with oneself. Monitoring consciousness seems to be the concept of meta-self-awareness.

The elements of the mind can also be categorized as follows:
> Phenomenal State: This is almost identical to [1] by definition.

> Representational State: This refers to the formation of an attitude toward a particular object.

> Action: This is the most complex and difficult aspect to define, and many different theories have been proposed to describe it.

So, which of these components constitutes the mind? In philosophical psychology, all of them are seen as necessary. After all, the functioning of the mind appears to encompass all of these aspects.
The concept of mental causation arises here, exploring how physical and mental elements interact with one another. For example, infinite meta-cognition—thinking about thinking about thinking about...—as seen in [3] illustrates interactions between mental elements, which we may call *psychic-to-psychic* causation. In [1] and [2], there are cases of *psychophysical* causation, where a mental element affects a physical element (e.g., recalling a memory from two years ago and reaching for a photo album), as well as *physical-to-mental* causation, where a physical element affects a mental state (e.g., seeing a picture of oneself and experiencing a sense of disillusionment).
From this analysis, it is clear that action [3] appears to have a connection with the mind. But is this really the case?

# Mind-Matter Problem
The Mind-Matter Problem, which involves attempts to address theories of the mind, can be divided into three major approaches (or more broadly, into two):
> a\) Reductive Physicalism: This stance considers the mind equivalent to bodily activity (i.e., a physical entity). Cognitive neuroscience, which views mental states as nothing more than chemical reactions among neurons in the brain, is a representative example of this perspective.

> b\) Epiphenomenalism: This stance regards the mind as a byproduct of bodily activity. If mental states closely interact with the brain, then the mind may be viewed as a kind of byproduct generated by the brain.

> c\) Emergentism: This stance is a dualist approach that entirely challenges (a) and (b). Emergentism posits that the mind is a separate entity, distinct from the physical entity, and that a mind can "emerge" when a physical entity becomes sufficiently complex. Attempts to explain brain phenomena as emergent properties of large clusters or systems using statistical field theory or chaos theory are representative examples.

In fact, (a) is merely an "extremely strong (radical)" version of (b). Imagine a ball (representing the brain) rolling on a road—according to (b), the shadow of the ball represents the mind, whereas (a) considers the ball itself to be the mind. The shadow of the ball has no causal effect on the movement of the ball on the road. Thus, one might consider the concept of the mind—at least as a physical phenomenon that is presumably reducible—completely irrelevant, focusing solely on material phenomena. Consequently, from the perspective of (a) and (b), the term *mind* refers to a phenomenon dependent on the physical world, and any soul independent of the physical world would be unequivocally irrelevant. Naturally, mental causation is also not a crucial factor for proponents of these stances, as mental elements in mental causation are considered equivalent to physical elements.
This kind of thinking is, in essence, the core of (b), which encompasses functionalism, connectionism, computational theories of mind (CTM), identity theory, anomalous monism, and many other concepts. Philosophers of psychology generally dislike this stance, and rightly so. Logical humanists are bound to be discontented with it. After all, the extension of (b) aligns with a view that dismisses all systems of human civilization and human existence itself as meaningless. If human thought and deliberation are nothing more than products of brain processes—if the mind is a *natural* phenomenon—then every action performed by humans is futile, and all human language is reduced to mere gibberish. In other words, according to the logic of (b), humans could no longer engage in moral evaluation, criticism, accountability, or appeals regarding anything at all. Just as we cannot hold lightning accountable for striking someone, no human could be held responsible for any action, regardless of its social implications.
If this reasoning holds, ethics, history, literature, and the arts would be reduced to collective delusions, and sociology and law would need to be abolished. With this line of thinking, formal logic—since it was invented by humans—along with symbolic logic-based pure mathematics and physics, and all the scientific and engineering disciplines reducible to physics, would also be deemed meaningless. Even metaphysics would devolve into mere nonsense. Ultimately, under the claims of (b), everything humans do becomes a grand exercise in futility. How horrifying and absurd a notion this is!
Furthermore, (b) suffers from a fatal logical inconsistency. Suppose a person A claims to hold the stance of (b). They could assert that the mind is dependent on the physical world, meaning that a mind, as an abstract entity independent of the physical world, does not exist. However, by this logic, the "self (I)"—which is also an abstract entity independent of the physical world—cannot exist either, and physical world-dependent abstract entities must be mere meaningless collections of matter. Yet A, by considering themselves to have a "self," is asserting (b). According to (b), the proponent A's mind is also a physical world-dependent abstract entity, which makes A's assertion meaningless. Therefore, A's assertion ends up affirming and simultaneously denying itself.
Most proponents of physicalism and epiphenomenalism inevitably find themselves trapped in such an impressive logical contradiction. This fundamental flaw is a primary reason why mainstream philosophers of psychology reject (b). The mainstream theories in neuroscience and psychology, which view consciousness and the mind as freely occurring information processing algorithms within the brain, also share this limitation.
Meanwhile, emergentism (c), a stance that is somewhat antithetical to (b), offers a rather unique perspective. It posits that there exists a mind independent of the physical world, and that this mind has no causal relationship with physical entities dependent on the physical world. However, from the perspective of scientists, this notion may prompt an instinctive reaction of "What on earth is this nonsense?" Therefore, the main issue with (c) lies in how one could prove the existence of a mind independent of the physical world. For example, consider the concept of a zombie that appears frequently in horror films—a being whose consciousness has died but whose body continues to move. Such an entity does not exist in reality, nor can we create it to demonstrate its existence. Hence, these arguments, based solely on the possibility of existence, may appear to be metaphysical, if not outright nonsensical.

![CEA](https://i.imgur.com/Y5gTz6f.png)

The Causal Exclusion Argument can be used to summarize this debate in a simple diagram. Specifically, if a neural state (NS) induces (supervenes upon) an experiential state, and if a neural state (NS*) induces (supervenes upon) an action, then according to (a), 1\) = NS and 3\) = NS\*. If we assume that NS\* is the cause of an action and that the experiential state exists, then the experiential state induced by NS has no causal influence on the outcome. Conversely, if we assume that the experiential state does not exist, then it is merely a physical state—NS. Emergentism, particularly substance dualism, renders any claim in this scenario meaningless, no matter which option is chosen. As a result, this introduces a significant flaw into any justification of mental causation within philosophical psychology.

# Further Discussion on Emergentism
However, the logic of (c) may have more significance than it initially seems. Specifically, "British Emergentism," which is also known as property dualism, appears to be such a case. Consider, for example, an object with a mass of 10 tons resting on a road. This ball is attributed with the property of heaviness. According to (c), the position of property dualism argues that the physical property of 10 tons of mass and the property of heaviness are entirely different, having no mutual influence and being irreducible to one another.
This argument seems to echo discussions about the connection between mathematics and the real world. For instance, explaining how the physical world fits mathematical descriptions so well is quite a challenge. We might agree that nature *does* mathematics rather than philosophy, but exactly why this is the case remains a mystery.
If mathematics were part of the physical world, humans would have discovered all of mathematics purely through empirical experience. Historically, numbers such as natural and whole numbers were discovered by people counting physically—thus experience-dependent. However, much of mathematics beyond this is not experience-dependent. Not all mathematical systems are countable; it is impossible to empirically discover the concept of transfinite numbers as studied by Hilbert or Cantor. Pure mathematics like mathematical logic, topology, or complex analysis cannot be demonstrated experimentally. Mathematics contains far more concepts discovered through imagination rather than hands-on experimentation.
Some argue that these mathematical concepts are *proven* by physics. However, this is demonstrably untrue. If the claims were accurate that mathematical systems and physical-world experience match up precisely, then Gödel's incompleteness theorems—which showed the systematic impossibility of proving all truths within a system—would have led to the collapse of the physical world. Yet the real world remained intact after Gödel, Church, and Turing emerged. Even Wittgenstein discussed this at length in his philosophy of mathematics. A simpler example would be the claim that physics *proves* the existence of a mathematical system: it would be equivalent to saying, "The real world should only validate the proposition 1 + 1 = 2, and not the proposition 1 + 1 = 10." These two propositions may seem contradictory, and classical logic does not allow for both. However, we know that these two propositions can coexist—1 + 1 = 10 is valid in a binary system, as proven by the development of modern computing. Such propositions are now acceptable under non-standard logic or quantum logic after developments beyond classical logic.
We intuitively understand that the collapse or reestablishment of a logical system has no impact on the physical world. While this discussion may seem digressive, the conclusion we reach is that while some parts of mathematical discovery are experience-dependent, others are experience-independent; thus, mathematics cannot be entirely dependent on the physical world. How, then, does mathematics exist in such a way, and how do we humans engage with it? There are two main hypotheses. One view is the transcendent view, which holds that mathematics is entirely independent of the physical world and has no relationship with it whatsoever. However, this view seems inadequate, given how extraordinarily well mathematics is used as a tool to explain natural phenomena. Thus, another view is the Kantian approach: mathematics is independent of the physical world, but it is an a priori concept for the physical world, and we can somehow perceive it (though we do not yet understand how exactly).
As a result, interpreting the relationship between mathematical systems and the physical world in this manner can be quite convincing, and I find that (c) is making a similar type of argument. Rather than claiming that there exists a soul or some independent mind, it suggests that psychological properties that lead us to think of ourselves as "I" indeed exist. These psychological properties—just like the relationship between mathematical systems and the physical world—are independent of physical properties, do not influence each other, and yet somehow manifest in the physical world. This is what British Emergentism argues (assuming I have correctly understood it). While opinions may vary, (c) seems more promising in the long run compared to (a) or (b).


# The Panorama of Mathematics
Imagine an aquarium filled with countless goldfish and fishbowls. In this setting, while there are always enough fish and bowls, we have no way of knowing the types or quantity of goldfish present, nor can we distinguish between them. Theoretically, even if there are an infinite number of fishbowls and there is no "rule" that determines how to select a specific goldfish from each bowl—even if distinguishing one goldfish from another is impossible—could such an imaginative system still exist? Interestingly enough, we find systems like this closer to us than we might think. The axioms of mathematics are, in a way, akin to such an aquarium. The Axiom of Choice is precisely this sort of principle. Often called Zermelo’s Axiom of Choice, it is one of the most controversial yet crucial axioms in mathematics, underpinning many theorems used in algebra and topology.
To accept the Axiom of Choice means agreeing to use a hypothesized selection function, denoted as f, in proofs, as though it "exists" in some sense, even if we cannot provide an explicit example or a clear algorithm for it. Set theory, a concept that one might encounter in secondary education through Cantor's set theory, can be developed on such axiomatic grounds. This approach is known as axiomatic set theory. The impetus for the development of set theory stemmed from the precarious state of Cantor’s theory of sets and his diagonal argument, which faced paradoxes like Bertrand Russell's barber paradox. Such paradoxes in mathematics evoke a chilling realization: "If all of mathematics rests on such fragile foundations, if we can trust none of its evidence, then what can we possibly believe in?"
Hilbert sought to design a world of perfect arithmetic axioms, yet that world fell apart under several studies of incompatibility. One of the pioneers, Turing, leveraged operations similar to those used by Russell in the barber paradox to address the Halting Problem. Turing’s use of automata, like his own Turing machine, resolved this issue. The work of Hoare & Allison excellently documents how Turing demonstrated that the problem of predicting whether a given program will halt after a finite number of steps is undecidable.
> (a) Consider a program `T` that functions as an automaton. We define a function that returns `true` if `T` halts normally and `false` otherwise. For instance, the function `terminate(x, T)` would take an arbitrary string `x` as input and run `T`; if it halts, the function returns true, otherwise, it returns `false`.

> (b) Next, define a new function `hetero(f)` that takes T as input. If `terminate(T, T)` returns `false`, `hetero(f)` returns `true`, otherwise it enters into an infinite loop.

> (b') If `terminate(T, T)` completes and returns `true`, the hetero function runs forever. Conversely, if `terminate(T, T)` does not complete and returns `false`, hetero returns `true` and halts.

> (c) Now define `terminate(R(hetero), R(hetero))`, i.e., `hetero(hetero)`.

> (c') If `hetero(hetero)` terminates, `hetero` must return `false`. However, since `hetero` itself is the input, `hetero` should loop infinitely, which is contradictory.

> (c'') Conversely, if `hetero(hetero)` runs indefinitely, the input `hetero` should return `true`, which also leads to a contradiction.

> (d) Therefore, this function cannot be implemented.

Another type of abstraction, one that might arise from such experience, concerns simple isomorphic systems. I recently found myself intrigued by the speculative narrative presented in the film Moonfall. Although the concept of the moon colliding with Earth depicted in the movie isn’t particularly scientific, I once used this idea as a topic for an essay back in high school. Despite its amateur nature, one of the points of interest in my earlier calculations was how, due to conservation laws, I had to use parameters to derive functions. Such work is often called *technique.* Figure: A function derived using the law of conservation of angular momentum in polar coordinates (to give a quick calculation result regarding the apocalyptic scenario: if, for some reason, the moon deviated from its predicted orbit and was drawn toward the Earth like the Rutherford model, humanity would have approximately 638 hours before extinction).
The amusement in such theories lies, at least in part, in the parameters. A function composed of traditional variables takes on the same form when constructed with newly designed unit vectors as parameters. Almost every solution in mathematics is composed of such isomorphic techniques. For instance, Hamilton’s equations in phase space, the Euler-Lagrange equations in generalized coordinates, and Newton’s equations of motion can all be described in structurally similar terms. Wave mechanics and matrix mechanics, while mathematically formulated in completely different ways, yield exactly the same conclusions. Thus, two major methodological perspectives arise in science: either one element is used consistently within similar subsystems, or one element is employed across distinct layers of different subsystems.
Heisenberg’s Physics and Philosophy traditionally explains that the physical system of physics is divided into four closed axiom systems—Newtonian mechanics, thermodynamics, electromagnetism, and quantum theory. These systems share interesting interrelationships: for example, the third theory reduces to the first as the speed of light approaches infinity. When Planck’s constant is infinitely small, the third theory becomes the fourth. Parts of the first and third theories are included a priori in the fourth theory. The second theory, being a consistent set of properties invariant under spatial transformations (such as rotations, Galilean or Lorentz transformations), aligns with all closed axiom systems. For a set of concepts to qualify as a closed axiom system, a consistent representation must be found within that set. Therefore, if physics borrows the language of mathematics, these axioms must be free from contradictions when mathematically expressed within the system. Afterward, physics should be able to use these systems to describe a broader range of phenomena.
Even if concepts within the set are clearly defined in relation to each other, their relationship with nature may still remain ambiguous. The limitation, therefore, is that specific concepts may fail to perfectly describe observed phenomena—something that must be deduced from experience. Thus, the many phenomena within the realm of experience must correspond to the multitude of solutions derivable from mathematical equations.
This explains why physical concepts and their associated laws must effectively describe other natural phenomena (otherwise, new perspectives beyond physics would be required). Representing the domain of experience through a consistent set of concepts, axioms, definitions, and laws that can be expressed mathematically is essentially akin to isolating a certain relational set and treating it as an ideal entity. Yet, such *clarity* does not guarantee that the axioms accurately reflect reality. The problem may turn out to be more profound than it initially seems when reduced to mere symbolic manipulation. If we unearth a system in the image of some part of mathematics—such as formal numerical manipulation rules—how can we be sure the system is true? If the purpose of generating such systems is the study of new experiences, how do we demonstrate the perfection of these techniques? Gödel’s First Incompleteness Theorem offers a metamathematical proof regarding the consistency of such axiomatic systems. However, rather than achieving its intended results, Gödel’s theorem shocked the mathematical community with its assertion that consistency could not be proven within the axiomatic system itself.
Thus, the Halting Problem forms a nearly identical structure to the Incompleteness Theorem. In his proof, Turing actually used corresponding ideas akin to Gödel numbering. Gödel’s First Incompleteness Theorem can be explained using Gödel numbering as follows:
> (k) Consider a mathematical statement G: "G: There is no proof for G." The metamathematical proposition is translated into a proposition using symbols and variables.

> (l) "The set of sentences with Gödel number x is a proof of the proposition with Gödel number z" is represented by D(x, z), and "The Gödel number of a proposition obtained by substituting variable y with x throughout a statement with Gödel number x" is expressed as S(x, 17, x).

> (m) Here, "G is unprovable" can be represented as ~(∃)D(x, S(y, 17, y)). If we define g = S(y, 17, y), then G states that G is unprovable.

> (m') If G is false, G must be provable, leading to a contradiction.

> (m'') If G is true, G must be unprovable, leading to another contradiction.

> (n) Therefore, the proposition G is "G is unprovable."

If physics is a kind of methodology, then the idealization process of mathematical propositions corresponds to the system's rules. If the world is a system, physics becomes the rule that governs that system. But the world is so complex that imagining whether its relationships can be precisely defined by a mathematical expression is difficult. As Gödel's work shows, even mathematics itself is incapable of verifying its own truth. The incompleteness of axiomatic systems is no exception, even for science.

# Physics and Philosophy
There is an interesting discussion linked to idealization in *Physics and Philosophy*. At least if such idealization is part of the human language about nature, the structure of science essentially becomes analogous to the form of art. Though the clarity of mathematics cannot strictly embody the formal rules that define the structure of art, the foundational elements of pure art are indeed closely intertwined with the aesthetics of mathematics. For instance, in Rudolf Arnheim's Art and Visual Perception, a study of principles like balance, symmetry, form, space, and movement reveals the mathematical and psychological foundations underpinning artistic composition. However, it seems that appreciating art demands a level of consciousness distinct from, and perhaps far removed from, the foundational disciplines that are more rigid and systematized.
The movements of art, aimed at comprehending reality, undergo an extended process of idealization similar to that of science. Yet unlike science, which often seems to pursue something permanent over an extended period, an individual work of art may appear devoid of an enduring pursuit. Scientific discoveries are sometimes incidental or achieved regardless of the identity of the researcher, but artistic movements are enduring only for those artists who participate in them. The paintings of Da Vinci, the symphonies of Beethoven, the plays of Shakespeare—none of these could have been invented or created by anyone other than their respective creators. This characteristic suggests that art cannot be entirely captured within a standardized set of norms.
However, art emerges from the interaction between the artist and the spirit of the times—Zeitgeist—which, intriguingly, might be independent of the actual historical period. The forms of a particular movement are eventually realized in the works of artists who can represent these elements in an understandable way. From this perspective, the methodologies of art and science do not seem so different after all. Both science and art are committed to developing a framework for interpreting aspects of reality over several centuries.
Of course, not all systems share the same rules. While something as grand as Peano’s axioms might underpin basic mathematical systems, the norms for things like game theory or chaotic sculptural works might belong to a more complex, higher-level system. This distinction makes interpreting such systems even more challenging. The domain of art lies at such a high level that explicit explanations are often impossible. Take, for instance, René Magritte’s The Two Mysteries, which depicts a pipe. Is it a pipe or not? Is it merely an image of a pipe, or does neither the pipe nor its representation truly exist? It challenges us with metaphysical imagination about what is a representation and what is not. Yet, when confronted with such a work, we don’t necessarily perceive a clear structure; instead, we often experience an intuitive feeling of something profound—something that even the artist might struggle to explain.
In Looking at the World Through an Artist’s Eye, this phenomenon is linked to representation. "How do artists draw? Is there some unique ability in the way artists see the world?" This curiosity can be succinctly summarized by explaining S. Vogt's research on visual perception. What is the most effective way to improve drawing skills for people who are not good at drawing in a short period? The answer is to teach them not to *conceptualize* the object being drawn but to *represent* it. For example, when drawing an apple, focusing not on identifying it as an apple but on the lines, shades, shapes, and contours visible in the image of the apple allows for more realistic and three-dimensional drawings. Representation shines especially when the concept of the object being drawn is abstract. When trying to express a metaphysical subject that cannot be seen, we often bring together and reconfigure images from a multitude of experiences acquired throughout our lives into a two-dimensional form.
The difference between an artist and a non-artist lies in how they view the world. Artists tend to observe the overall scenery, while non-artists focus on individual objects. This suggests that non-artists conceptualize images, whereas artists represent them—attending to things like color or contour. Consequently, artists, by perceiving the world more directly—as a collection of forms and colors—can break away from existing patterns of behavior to draw what they see.

# Imitation Game and Creativity
If the originality of representation lies somewhere between imitation and creation, where exactly does imitation end and creation begin? To start, an artist's creative act does not arise from *nothingness*; rather, it emerges within a continuum of imitation—often leveraging accumulated knowledge across generations. But whether producing something entirely *new* and unlike anything that came before truly distinguishes itself from an enormous volume of imitation is an open question. If distinguishing the two through any systematic approach proves impossible, we might need to revisit the original debate: what does art mean to humans in the first place?
So far, the question of "what is imitation and what is not?" has always been predicated upon the assumption that art is a uniquely human domain. But is the creative act of humans, like the product of algorithms—a sharp blend of repeated imitation—truly distinct from this? Is there a clear answer to this question? This inquiry leads to something similar to the debate on whether we should recognize AI-created works as art. If we begin expanding the category of artists beyond just humans, the works of AI, which could be seen as an experimental embodiment of continuous imitation, might be the closest to the original essence of art.
Consider an analogous scenario: Wolfram Alpha, a computational engine, features a music composition program called WolframTones, which is based on Wolfram Language. Here, the user selects a few musical codes, and the program creates music from these as a bitmap. Unlike an algorithm that simply mimics existing musical data, this program itself composes new melodies, using algorithms derived from musical features of various genres. It's like a Turing machine where bitmaps function as the musical score. In this context, I consider such a program to be equivalent to a Turing machine for composing. Let’s say there is a hypothetical machine called **M**, which is more advanced than WolframTones and can generate fractal-like musical bitmaps. In this case, we might say that **M** is creating mathematical and artistic music as well as profoundly musical and mathematical art.
Now imagine an A-mode Turing Test that attempts to determine whether a piece of music is composed by a machine or a human. This mode operates like the conventional Turing Test, which uses statistical logic to determine whether a machine's behavior resembles human intelligence. If the music produced by **M** evokes an artistic sense comparable to that of music created by human composers, then **M** has a high probability of passing the A-mode Turing Test.
However, when we judge a work of art based solely on the piece itself, spectators often engage with the work in ways that differ from the artist’s original intent. Even if it cannot be precisely articulated in language or any other form, what spectators feel during this engagement becomes their experience of the artwork's artistry. As with the conventional Turing Test for assessing machine intelligence, the A-mode Turing Test for evaluating artistic capability requires human judges to assess a work’s artistry based on whether it appears to possess what we consider artistry. Consequently, in the A-mode Turing Test, the nature of artistry almost guarantees that **M** will pass.
If we separate the enjoyment of art into the roles of creator and observer, the relationship between AI and art also aligns along these lines: AI as the creator and humans as the audience of the work. If art must be judged from both perspectives, then at least from the observer's point of view, AI-produced works can indeed be highly artistic. But can we know whether AI itself experiences emotions or simulates sentiments and fleeting feelings? We cannot tell.
Thus, even if observers' judgments about a work influence its recognition as art, the standards of artistic quality cannot be left solely to the observers. On the other hand, if artistic practice and the artwork itself become complete only through *interaction between the creator and observer*, what happens when the subjectivity of the creator comes into question? Does the work then become art, or does it become something else entirely?

# Where Does Creativity Come From?
New ideas can be conceived when considering a higher-level, ambiguous system of consciousness, particularly in the context of heuristics, intuition, and insight as they relate to cognitive psychology. Lofty inquiries originating from profound intellectual pursuits can be viewed as manifestations of consciousness functioning as a mechanical mechanism. Yet, to fully regard human consciousness as solely rational seems lacking; similar to the difficulty in expressing artistic inspiration through clear, linguistic means, something inherently feels missing.
One piece of evidence for this limitation comes from heuristics, including biases that operate at the automatic processing level—much like Freud's notion of the unconscious. While heuristics can be efficient from an information-processing perspective, they do not necessarily lead to rational thinking. The presence of cognitive leaps or errors in intuitive judgment is due to the role heuristics play in the composition of intuition. However, human intuition—though difficult to precisely define—often proves surprisingly persuasive. Intuitions are frequently instantaneous leaps of thought or unconscious inferences derived from a priori knowledge or past experiences. In that sense, distinguishing intuition from insight is not always clear-cut. Yet, relying solely on intuition can leave something wanting. In some cases, intuitive thinking is insufficient for problems that require insight; it is typically the controlled processing corresponding to insight that becomes essential for effectively solving such problems.
In Wolfgang Köhler’s insight learning, a solution derived through insight is said to be retained in memory even after just one occurrence. Here, insight refers to solutions that emerge suddenly from an understanding of the problem in its entirety. A representative example where insight is essential might involve physical reasoning. To illustrate with a mundane issue related to intuition, some people might simply end up daydreaming or lying down to rest when presented with a problem; these individuals can be seen as having failed to achieve insight learning for the proposed problem. On the other hand, there are those who strain their minds and solve an old, worn-out problem, and thus gain insight into it. In this context, I have come to believe that the essence of insight isn’t necessarily about whether or not one can solve the problem. Whether one gains insight through tackling the problem or by stepping away from it, we end up with some form of insight regardless.
When faced with a problem, we as humans will, in one way or another, develop an awareness of our actions. In My Perspective on the Relationship Between Creator and Creative Output, there was an assertion that at least for automatons, such meta-cognition is fundamentally impossible. Viewed in this way, it is quite striking that humans' metacognition appears largely independent of any specific knowledge they may or may not possess. Implementing human cognition, as represented by integrated information theory, is an extraordinarily complex endeavor. To replicate the architecture of the human brain's neural network using a machine that follows the von Neumann architecture would require an information-processing system entangled across several levels. Such a setup may involve constructing the machine’s operating system in a way that closely resembles the neural networks of the human brain.
However, it seems that even the most advanced artificial intelligence, regardless of how well it predicts outcomes in a game, cannot quite match the intricacies of human intelligence and the mysterious interplay between knowledge and ignorance—a balance often compared to walking a tightrope. If it were possible to implement a mechanism that resembles the human brain, at what point would we say an AI programmed as a system of possibilities—capable of exhibiting behaviors emerging from rules amidst mixed outcomes—is *thinking for itself*? When does AI break away from being an HCI system, acting beyond the mere commands of humans, to genuinely possess consciousness? Is it even structurally possible to comprehend something beyond the *meta-* system that transcends itself? And if it is possible, how would it be achieved?
At this level, can humans also attain insights into another (*meta-*) system that transcends the human framework? If it is possible, then what of the next level (*meta-meta*)? And after that (*meta-meta-meta*)? And then, what about the level beyond that (*meta-meta-meta-meta-...*)? Where do the rules of cognitive insight originate?
I believe that understanding where consciousness comes from becomes particularly crucial in these contexts. If imperfection exists in systems designed to align with nature, does that imply a fundamental flaw in those systems themselves? If metacognition operates on intuition, should we conclude that human consciousness is fundamentally flawed? This speculation contains a significant paradox, one that is unlikely to be resolved anytime soon.

# Theory of Consciousness (ToC): A More Scientific Approach
The theory of the mind is also known as ToC or ToM. The term *mind* is frequently used in philosophy of psychology, whereas in the scientific field, *consciousness* seems to be the preferred term—perhaps because *mind* appears unscientific. In this essay, I will use the term ToC.
As mentioned in previous essays, the current mainstream perspective in the scientific community is a biological (especially neuroscientific) and physical view. Given the subject matter, it appears that research is more active in the biological domain than in physics. [Here](https://www.sciencedirect.com/topics/psychology/theory-of-consciousness), I will explain the various theories that exist (selecting only those that align with physical phenomena among neuroscientific theories). To date, the most prominent theories are the Integrated Information Theory (which sees the workings of human consciousness akin to an input-output maximized optimization process) and the Computational Theory of Mind.
In early research on cognitive science, studies on human consciousness focused primarily on the brain and the states of neural networks that constitute it (Neural Correlates of Consciousness). This was unsurprising, given that, even today, we assume that human intellectual activity occurs in the *brain* and it indeed seems to be the case. Although we cannot pinpoint the exact location or mechanism that triggers the system of intelligence, we can at least be certain that it is closely related to the brain. Although NCC is criticized in philosophical circles, it is treated almost as fact within the scientific community, making it a widely supported assumption and thus empowering epiphenomenalism. There have also been studies that focused on specific areas, such as the prefrontal and parietal lobes, observing brain activity or examining the spatial connection patterns of neural networks algebraically as if the components of the brain were individual nodes. The most impactful outcomes of CTM were probably Bayesian & Kolmogorov algorithms and artificial neural networks (NN), as they offered a wealth of practical applications. Moreover, the strong internal consistency of syntactic mapping, preservation of logical compounds, and relativization of quantifiers in physics made extending this framework relatively easy. Effective Field Theories could also be considered an example of this. Fortunately, a neighbor once posted an article about NN-QFT, which I found interesting at the time.
However, the issue with the NCC-based framework mentioned above is that its limitations are far too evident. IIT does not yield outcomes that could be described as *consciousness.* With the advent of GPT, these limitations have already been exposed... unfortunately. Of course, if the sole purpose is technological development, then there's no problem; we could simply treat artificial intelligence as a tool. Over time, the technology will become more sophisticated, and it will likely "almost" converge to human intellectual performance. (Just three days ago, DeepMind unveiled [AlphaGeometry](https://www.nature.com/articles/s41586-023-06747-5), capable of solving geometry problems at the level of International Mathematical Olympiad winners.) In summary, IIT-based theories of consciousness serve as an excellent tool for enhancing research efficiency. However, they have failed in the aspect of *attempting to artificially implement intelligence.* It remains to be seen how meaningful machine learning will be in cognitive science in the future. It might turn out to be a temporary trend, much like the DFT or ab initio automation sections that shone for a while and then faded away.
It is true that IIT-based ToC is nearing its limitations. Therefore, we could potentially attempt [a new approach](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7517149/) that has yet to be tried. Of course, there is no guarantee that attempting a new theory will result in anything superior to existing ones. Cognitive science is just taking its first steps—much like the situation when quantum mechanics emerged 100 years ago. At that time, physicist Wolfgang Pauli made this humorous remark: "Until now, no one has known any hypothesis better. Therefore, those who are not yet familiar with the completed state of science may find it easier to determine the direction of their exploration. Of course, ignorance does not guarantee success."
From the outset, there have been numerous theories that attempt to explain consciousness besides IIT, such as the [Quantum Integrated Information collapse model](https://link.springer.com/article/10.1007/s10701-015-9905-6), [Global Workspace Theory](https://www.sciencedirect.com/science/article/abs/pii/S0079612305500049), [Higher-order Theories of Consciousness](https://plato.stanford.edu/entries/consciousness-higher/), Electromagnetic Theory of Consciousness, and [the QFT of Brain States](https://plato.stanford.edu/entries/qt-consciousness/#VitiFreeQuanFielTheoBraiStat). There are many theories, but not all are practically useful. Some theories are unverified, some assumptions are virtually impossible to validate, some are overly abstract and hard to apply, while others are simply personal opinions of scholars (e.g., Orch-OR, Consciousness Field Theory, p-Adic QM (haven't looked into this yet), Topological Geometrodynamics (what is this?); etc.). The [Temporo-spatial Theory of Consciousness](https://plato.stanford.edu/entries/qt-consciousness/#VitiFreeQuanFielTheoBraiStat) is also an interesting theory. But why is [Category Theory](https://arxiv.org/abs/0903.0340) so frequently used among these countless theories? After doing some research, it seems that to approach consciousness from a physical standpoint, one must define it physically. A model must satisfy the following characteristics of consciousness: 1\) self-organization, 2\) self-similarity, 3\) complementarity (duality), 4\) complexity, 5\) causality, and 6\) non-locality. To achieve this, one must inevitably draw upon knowledge of topology or formal science from physics. Concepts like sheaf, type, and category are excellent for bridging different disciplines, which explains their use here ([computational trinitarianism](https://ncatlab.org/nlab/show/computational+trilogy)). By the way, this somehow seems to inherit Hilbert's formalist program—isn't this strange? The theory attempting to explain consciousness [using Grothendieck topology](https://www.taylorfrancis.com/books/mono/10.1201/9781003067344/fundamentals-algebraic-microlocal-analysis-daniele-struppa-goro-kato) belongs to mathematical formalism, and examples might be the [Wolfram Physics Project](https://www.wolframphysics.org/bulletins/2020/08/a-candidate-geometrical-formalism-for-the-foundations-of-mathematics-and-physics/) and [Categorical Quantum Mechanics](https://arxiv.org/abs/0808.1023). The former even explains synthetic theory of homotopy type, which complements the limitations of classical logic and existing ZFC axiom-based set theory.
I'm writing like I'm collecting stamps in a haphazard fashion here, but is there a way to look at ToC in a more naive manner? In my opinion, if we organize the current approaches of scholars, consciousness could be largely divided into 1\) analogy and 2\) abstraction. One of the scholars who laid the foundation for this was Douglas Hofstadter. Incidentally, in Surfaces and Essences, Hofstadter mentioned syntactic mapping in physics—something I just mentioned—as an example of analogy (The Ubiquity of Analogies in Physics... although I can't seem to find any resources on it even by searching. It might be worth checking out. It seems that theories of formalism like this are hotly debated in philosophy of physics. Homotopy Type Theory/CT, used in string theory, appears to be a particular target of such criticism, and if that's the case, TTC may soon face similar criticism... [Online discussions illustrate this viewpoint quite well.](https://golem.ph.utexas.edu/category/2013/10/the_hott_approach_to_physics.html))

# The Difficulty of Defining Consciousness 'Scientifically'
Why is studying consciousness such a complex task? Let's delve into a fundamental question this time. Is *consciousness* itself even a suitable subject for scientific inquiry in the first place? Science always assumes the existence of an *objective world, an objective system* that is separated from subjectivity. The subject of scientific inquiry is usually something objective, like nature. But, strictly speaking, human consciousness is always *subjective,* isn't it?
It's quite curious how humans can communicate their thoughts to one another, using both verbal and non-verbal expressions. How is it possible for different living beings to communicate? As humans, we might answer that we can *infer* each other's minds because we share the same physical mechanisms. (Is this why analogy is the core of consciousness?) In any case, since such inferences are often quite accurate, humans sometimes even say they *understand* each other's minds. However, by this reasoning, is it possible to infer the minds of non-human entities like bats or cats? Humans have binocular vision that can only perceive the visible spectrum, and we have neither tails nor wings—how close can a human get to *knowing* what it feels like to have a tail or wings or to see ultraviolet light? It might be almost impossible.
This could be the essential problem of ToC. In the end, the basis for the assumption that *an objective world exists* is limited to human experiences—things we see, feel, touch, and hear. This is why science is sometimes called an *empirical science.* However, if human *experience* itself is subjective, then assuming *an objective world exists* based on the information we gain from seeing, hearing, and touching might be a case of circular reasoning... [Nagel's argument](https://www.jstor.org/stable/2183914?origin=crossref) and [Chalmers' Hard Problem of Consciousness](http://www.newforestcentre.info/uploads/7/5/7/2/7572906/chalmers_-_the_conscious_mind__1996_.pdf) may be related to this issue.
There is also an argument that all things humans declare are merely models and not representative of the system itself. This is a problem worth contemplating, as it arises in various areas related to cognitive science (e.g., the P-NP problem, philosophical interpretation of the Rabin-Scott theorem). It is indeed quite a headache.
At least now we know that the theory of consciousness is far more complex than it seems; since diving too deep yields no answers and only leads to endless speculation, perhaps the best approach at the moment is to focus on the phenomenal aspects. We need to return to perspectives 1\) and 2\). After much contemplation, it seems to converge to the question of *How do humans think?*
This field, no matter how deeply explored, offers no clear answers and only leads to more conjecture.

# Mind and Language
In the end, consciousness might be about *thinking* and *forming meaning (concepts).* So, do we think in language? First of all, we need to understand what exactly *language* is, but that's not an easy question. Narrowly speaking, language refers to natural language as studied in linguistics, but there may be no reason to limit the concept of language to natural language alone. Broadly speaking, a systematic set of rules used to express meaning using signals could also be considered language. A scientific approach to this subject focuses not on *What is language?* but rather on *What is language for?* (I'm not sure if this is related to the Linguistic Category Model, but I heard there's already [a model that implements a lexicon using category theory](https://golem.ph.utexas.edu/category/2018/02/linguistics_using_category_the.html)... It might even be possible to link this to CQM.)
Seen from this perspective, sensory information gathered through reading and writing, speech production, and auditory perception might just be a part of countless environmental factors for assuming the most suitable form of communication rules for a given environment. For instance, let's assume that extraterrestrial beings evolved with a bat-like structure exist in the universe. Their method of acquiring *sensory information* would certainly differ from that of humans. This is because their language structure would have evolved from a bat’s echolocation mechanism, rather than the vestibular system of primates. However, as mentioned earlier, it is almost impossible for humans to infer the mind of a bat. Even if there were intelligent extraterrestrial life forms, unless they were very similar in physical structure to humans, there would be no linguistic way for humans to communicate with them. If this assumption holds, it would be the same for strong artificial intelligence as well.
There is no doubt that language is a crucial factor in expressing and conveying meaning, and that it works surprisingly well as a medium for communication. However, it doesn't seem that humans necessarily *think in language* ([criticism of the Sapir–Whorf hypothesis](https://linguisticus.wordpress.com/the-sapir-whorf-hypothesis/)). The probability is high that before language, one first brings to mind the *meaning* that language refers to. Language is rather a *means* for organizing or externally expressing meaning, but not meaning itself. Hence, ToC, from this perspective, should be approached conceptually rather than linguistically.
This naturally leads to the question of what *pure thinking* might be. What form does a *concept* take, if anything at all?

# Mind and Imagery: Logical Thinking, Mathematical Thinking, Visual Thinking
If such an abstract form (mental imagery) is not language, then could it be some sort of image? This was an intriguing hypothesis. First, it turns out that human visual information is more cognitively distorted than expected. Humans do not perceive external physical information exactly as it is. Interestingly, however, we can [pattern this information](https://graybox.co/knowledge/blog/gestalt-principles-applied-to-design), which has had a significant impact on modern and contemporary art theories ([Gestalt principle](https://www.jstor.org/stable/1576669)). There is also the curious fact that [mathematicians who lose their sight](https://www.ams.org/notices/200210/comm-morin.pdf) often excel in topology. The pure form of thought for these mathematicians, who do not obtain physical visual information, seems to depend heavily on *shapes.* In other words, at the most basic level, the human mind likely resembles a topological structure rather than a physical entity with units like metric or volume.
Another point to consider is that the relationship between imagery and meaning is surprisingly complex. Images have three categories, and how the link between the two is forged determines whether they become a picture, a symbol, or a sign. On a related note, we must consider the relationship between logic and language. What is logic? After some contemplation, I believe *a set of systematic rules or a collection thereof* might be the closest definition. The concept of logic can be found in all intellectual activities carried out in language. In the case of mathematical logic, the field initially aimed to represent such logic with formal symbols to refine it to a high degree. Therefore, formal symbols used in analysis, among other fields, are akin to hieroglyphics—each minimum unit can encapsulate meaning. Because of this characteristic, formal symbolic notations can act as symbols or as signs depending on the situation. This is also discussed as an example of naive analogy in Surfaces and Essences, which hints at the potential for formal symbols to form visual translations. As mentioned in the link above, some blind mathematicians major in analysis and claim that they can visualize formulas like looking at pictures.
Coincidentally, a similar observation is made in art theory. In Rudolf Arnheim's Visual Thinking, an introductory perspective is addressed regarding the relationship between internally evoked mental imagery and visual imagery acquired externally. However, this does not mean that meaning is imagery. Just as language greatly influences human consciousness, imagery also significantly affects consciousness. However, that does not mean that human mental imagery is imagery itself.

# Where Does Meaning Reside?
In Douglas Hofstadter's *Gödel, Escher, Bach*, this question is traced back to another question: "Can we say that meaning is inherent in a message, or is meaning always created by the interaction between the message and a mind or mechanism?"
Conscious activity can be easily understood as analogous to listening to music. Consider the following:
> Music: Information composed of [sound].

> Record: Stores information corresponding to [music]. This information can be extracted using the [groove pattern] on the surface of the record. (Information storage medium)

> Turntable: Converts the grooves on the [record] into [sound]. In other words, it decodes the information stored in the record and realizes it physically. (Information realization medium)

Based on this structure, listening to music can be viewed as follows: First, we can say that there is a message, [music]. To understand what this message *means,* one must *decode* the information, and the surface of the record, which *contains* this music, is engraved with grooves. If a thin, pointed object is rubbed against the record's surface, one can *extract* sound information from the groove patterns. In other words, there is an isomorphism between the [groove pattern] and the [sound]. This isomorphism allows us to physically realize the music.
If we apply this perspective to conscious activities—like speech production—then:
> Mind: Information composed of [meaning].

> Brain: Stores information corresponding to the [mind]. This information can be extracted using [A] in the brain. (Information storage medium)

> Body's speech organ: Converts [A] in the [brain] into [sound]. In other words, it decodes the information in the brain and realizes it physically. (Information realization medium)

First, there is a message, the [mind], and there is a storage medium, the [brain], that contains it. Observing the act of speaking, we can say that the body acts as a realization medium that decodes the information. Therefore, as with the isomorphism between [groove pattern] and [sound], it is necessary to find [A—some pattern that projects the mind] in the brain that can be equated with [meaning].
Can we find a concept that can be reduced to a unit of *consciousness*? Such a line of thinking has been the approach of ToC so far. However, if *consciousness* doesn't have any units, then the initial approach itself might have been flawed... because consciousness may not be a *substance* or *state* but rather *the very form itself.*